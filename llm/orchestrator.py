from .prompts import USER_ANSWER_PROMPT   # ƒë·∫∑t trong prompts.py
from .state import StateManager
from .agent import FunctionAgent
from .function_registry import functions
from string import Template

"""
- T·∫°o c√¢u tr·∫£ l·ªùi cho ng∆∞·ªùi d√πng
"""

# -----------------------------------------
# Orchestrator: ƒëi·ªÅu ph·ªëi to√†n b·ªô workflow
# -----------------------------------------

class Orchestrator:
    def __init__(self, conversation_id: str, agent: FunctionAgent):
        self.agent = agent   # s·ª≠ d·ª•ng agent chu·∫©n
        self.state = StateManager(conversation_id)

    def resolve_params(self, fn, extracted_params, state):
        fn_info = self.agent.find_function(fn)
        if fn_info is None:
            return {}, []

        valid_params = fn_info["parameters"].keys()
        required_params = fn_info.get("required", [])

        # 1. Kh·ªüi t·∫°o c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß
        final_params = {
            "conditions": [],
            "orders": [],
            "limit": None
        }
        
        # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o
        extracted_params = extracted_params if isinstance(extracted_params, dict) else {}
        state_entities = state.get("entities", {}) if (isinstance(state, dict) and state.get("current_intent") == fn) else {}

        # --- X·ª¨ L√ù CONDITIONS ---
        extracted_conds = extracted_params.get("conditions", [])
        state_conds = state_entities.get("conditions", [])

        for p in valid_params:
            match = next((c for c in extracted_conds if c.get("field") == p), None)
            if not match:
                match = next((c for c in state_conds if c.get("field") == p), None)
            if match:
                final_params["conditions"].append(match)

        # --- X·ª¨ L√ù ORDERS ---
        # ∆Øu ti√™n orders m·ªõi t·ª´ AI, n·∫øu kh√¥ng c√≥ th√¨ l·∫•y t·ª´ state c≈©
        final_params["orders"] = extracted_params.get("orders") or state_entities.get("orders") or []

        # --- X·ª¨ L√ù LIMIT ---
        # ∆Øu ti√™n limit m·ªõi, n·∫øu kh√¥ng c√≥ l·∫•y t·ª´ state, m·∫∑c ƒë·ªãnh c√≥ th·ªÉ l√† 10 ho·∫∑c None
        final_params["limit"] = extracted_params.get("limit") or state_entities.get("limit")

        # Ki·ªÉm tra tham s·ªë b·∫Øt bu·ªôc
        final_fields = {c.get("field") for c in final_params["conditions"]}
        missing = [p for p in required_params if p not in final_fields]

        return final_params, missing



    # ------------------------------------------------------
    # Build final answer cho ng∆∞·ªùi d√πng sau khi g·ªçi function
    # ------------------------------------------------------
    def build_user_answer(self, user_query: str):
        if self.state is None:
            raise RuntimeError("State ch∆∞a ƒë∆∞·ª£c load. H√£y g·ªçi load_state(conversation_id)")
        
        # L∆∞u c√¢u h·ªèi ng∆∞·ªùi d√πng
        self.state.add_user_message(user_query)

        history = self.state.conversation.get("history", [])
        # STEP 0: chuy·ªÉn c√¢u h·ªèi m·ªõi th√†nh c√¢u ƒë∆°n nh·∫•t

        user_query = self.agent.rewrite_query(history[:-1], user_query)

        print("step 0: ", user_query)

        # STEP 1: ch·ªçn function
        fn = self.agent.select_function([], user_query)
        
        print("step 1: ", fn)

        is_fn = self.agent.find_function(fn)

        # Kh√¥ng c√≥ function ph√π h·ª£p ‚Üí ch·ªâ chat b√¨nh th∆∞·ªùng
        if not fn or fn == "none" or is_fn is None:
            full_answer = "Xin l·ªói, nh∆∞ng c√¢u h·ªèi c·ªßa b·∫°n kh√¥ng thu·ªôc ph·∫°m vi tr√°ch nhi·ªám c·ªßa t√¥i. N·∫øu b·∫°n c·∫ßn h·ªó tr·ª£ v·ªÅ lƒ©nh v·ª±c th·ªßy l·ª£i, h√£y cho t√¥i bi·∫øt!"
            self.state.add_assistant_message(full_answer)
            return full_answer

        self.state.update_state({
            "current_intent": fn,
            "status": "collecting",
            "entities": {},
            "missing": []
        })

        # STEP 2: tr√≠ch params
        fn_info = self.agent.find_function(fn)
        valid_params = fn_info["parameters"].keys()

        params = {}
        if valid_params:
            params = self.agent.extract_params(fn, [], user_query)

        print("step 2: ", params)

        self.state.update_state({
            "entities": params
        })

        final_params, missing = self.resolve_params(
            fn=fn,
            extracted_params=params or {},
            state=self.state.conversation.get("state")
        )

        self.state.update_state({
            "missing": missing,
            "status": "ready" if not missing else "collecting"
        })

        print("Final Params: ", final_params)
        print("Missing: ", missing)

        if missing:
            missing_descriptions = []
            for p in missing:
                desc = fn_info.get("parameters", {}).get(p, {}).get("description", p)
                missing_descriptions.append(desc)

            lookup_text = "\n".join(f"- {d}" for d in missing_descriptions)

            return self.agent.stream_llm_answer(
                USER_ANSWER_PROMPT["incomplete"].format(
                    lookup_result=lookup_text
                ),
                self.state,
                user_query=user_query
            )
        
        # STEP 3: g·ªçi function
        result = self.agent.call_function(fn, final_params)

        print("step 3: ", result)

        self.state.update_state({
            "status": "done"
        })
        
        status = result["status"]
        max_tokens = 256
        
        # Kh√¥ng c√≥ function ph√π h·ª£p ‚Üí ch·ªâ chat b√¨nh th∆∞·ªùng
        if not result or status == "normal":
            system_prompt = USER_ANSWER_PROMPT[status].format(
                result="C√¢u h·ªèi n√†y kh√¥ng c·∫ßn d·ªØ li·ªáu."
            )
            # note: s·ª≠a l·∫°i truy·ªÅn user_query
            return self.agent.stream_llm_answer(
                system_prompt=system_prompt,
                state_manager=self.state,
                user_query=user_query,
                max_tokens=512
            )

        # T·∫°o d·ªØ li·ªáu ƒë·ªÉ ƒë∆∞a v√†o prompt
        if status == "success":
            desc = result.get("field_descriptions", {})
            function_name = fn
            data = result.get("data", [])
            count_data = len(data)
            self.state.update_context(function_name, data)

            lookup_text = ""
            if isinstance(data, list) and count_data > 0:
                all_items_text = []
                # C√≥ th·ªÉ gi·ªõi h·∫°n data ƒë·ªÉ tr√°nh prompt d√†i
                for item in data:
                    lines = [
                        f"- {desc.get(k, k)}: {v}"
                        for k, v in item.items()
                        if v not in (None, "", "None", 0, "0") # Lo·∫°i b·ªè th√™m s·ªë 0 n·∫øu c·∫ßn
                    ]
                    all_items_text.append("\n".join(lines))
                
                lookup_text = "T·ªïng s·ªë k·∫øt qu·∫£: " + str(count_data) + "\n\n" + "\n\n---\n\n".join(all_items_text)

            # üëá B·ªî SUNG: x·ª≠ l√Ω suggestion templates v·ªõi params
            suggestions = fn_info.get("suggestion_templates", [])
            suggestion_templates = "\n".join(f"- {s}" for s in suggestions)
            max_tokens=1024

        elif status == "incomplete" or status == "not_found" or status == "summary":
            lookup_text = result.get("message", "")
            max_tokens=512
        else:
            lookup_text = ""

        # print('Data: ', lookup_text)
        # T·∫°o system prompt cu·ªëi
        system_prompt = USER_ANSWER_PROMPT[status].format(
            lookup_result=lookup_text,
            suggestion_templates=suggestion_templates if status == "success" else "Kh√¥ng c√≥"
        )

        # print("Final System Prompt:\n", system_prompt)

        # Tr·∫£ v·ªÅ d·∫°ng stream
        return self.agent.stream_llm_answer(system_prompt, self.state, user_query, max_tokens)
    

